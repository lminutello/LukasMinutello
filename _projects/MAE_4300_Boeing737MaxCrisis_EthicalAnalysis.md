---
layout: project
title: Ethical Analysis of the Boeing 737 MAX Crisis
description: Ethical Analysis of the Boeing 737 MAX Crisis for MAE 4300 Portfolio Assignment
technologies:
image: /assets/images/737MAX.png
---

 The Boeing 737 Max crisis refers to the series of crashes that occurred on Boeing 737 Maxs and the whole political and technical landscape that led to those moments. In an attempt to match the growth of its competitors, Boeing made several missteps with the launch of its new Boeing 737 Max. It would be apt to refer to the crisis as a “wicked problem”, or a problem that lives at the meeting point of tangible engineering challenges, personal beliefs and decisions, and large-scale cultural values. In order to better understand such a wicked problem, it is important to divide it into its core issues and classify those issues as being either material, individual, or organizational.
 
 The material facts refer to the technical/system elements and the design decisions that led to them. At the core, these are the direct cause of the failure of the plane. To better understand these facts, we must first understand what went wrong with the Boeing 737 Max. The crisis revolves around a series of two plane crashes, both of which involved the failure of the same subsystem, MCAS. MCAS (Maneuvering Characteristics Augmentation System) is a flight-control augmentation that automatically pitches the nose down if the angle of attack is high. The reason why MCAS was being used in the first place is that the chassis of the 737 Max was the same as the old 737, but the engines were larger, which altered the aircraft’s pitch behavior at high angles of attack and reduced the stick-force gradient, creating a tendency to pitch up near stall. The issue that occurred on the two crashes was that the angle of attack sensor provided erroneous data, and MCAS interpreted the aircraft as being at a dangerously high angle of attack, and the result was MCAS trying to force the plane down repeatedly. Further amplifying this issue was the fact that disabling MCAS required cutting electrical power to the stabilizer trim system, which also removed powered pitch-trim control and forced pilots to rely on manual trim under extreme aerodynamic loads, so the pilots would struggle to regain control once the plane was in a steep, accelerating descent, even if MCAS was disabled. Had there been an additional angle-of-attack sensor used for redundancy, the faulty data would likely have been rejected or flagged, preventing erroneous MCAS activation altogether.
 
 Why wasn’t this sensor in the plane? Why didn’t the pilots know how to stop it from spiralling out of control? Answering these questions requires looking beyond hardware and examining the individual and organizational factors that shaped these decisions. These two categories are closely intertwined, as individual actions can both influence organizational culture and reflect it. On an organizational level, Boeing was playing catch up to Airbus’ new launch, and wanted to satisfy potential buyers, who requested minimal pilot re-training requirements. In order to do so, the number of changes for pilots needed to be minimal, and Boeing requested that the FAA allow MCAS not to be explicitly documented in the FCOM, meaning pilots would be in the dark about MCAS and wouldn’t know how to deal with it properly. Even after the first crash, the Boeing bulletin and the FAA Emergency AD didn’t specifically mention MCAS, and a second crash occurred. The FAA claims that they didn’t see MCAS as a high risk area when inspecting the 737 Max and devoted more attention to higher risk areas, and perhaps this classification of low risk is why Boeing didn’t add a second sensor for redundancy. They also claimed it wasn’t novel because it was used in Boeing 767 military tankers, a comparison that overlooks the fact that those aircraft incorporated redundant sensor inputs, which makes it odd that it wouldn’t be required for another aircraft.
 
 What were the warning signs that Boeing could’ve found itself at the center of such a wicked problem? These warning signs are evident in the statements and actions of individuals involved in the debacle. The man at the front of the headlines was the former CEO of Boeing, Jim McNerney. He set the tone by consistently rewarding leaders who hit cost, schedule, and stock targets, which told the organization what really mattered. He backed decisions to reuse existing aircraft designs instead of starting fresh, pushing teams to work around engineering limits rather than challenge them. Over time, that taught people that raising technical concerns slowed programs down, while finding quiet, low-visibility fixes was the safer career move. Mark Forkner, Boeing’s chief technical pilot, played a role in downplaying the significance of MCAS in communications with regulators and pilot groups, while later indicating that he was not fully aware of the system’s expanded authority as development progressed.
 
 Ultimately, the Boeing 737 MAX crisis cannot be explained by a single failure or decision. It emerged from the interaction of technical design choices, organizational pressures, and individual incentives, making it a textbook example of a wicked problem in modern engineering. Understanding these layered causes is essential for preventing similar failures in the future.